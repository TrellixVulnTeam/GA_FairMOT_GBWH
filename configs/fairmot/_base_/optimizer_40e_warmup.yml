epoch: 40

LearningRate:
  base_lr: 0.0001
  schedulers:
  - !PiecewiseDecay
    gamma: 0.1
    milestones: [20,]
  - !LinearWarmup
    start_factor: 0.3333333333333333
    steps: 1000

OptimizerBuilder:
  optimizer:
    type: Adam
  regularizer: NULL
